---
title: Hello RAGer
published: false
---

Building workflows with LLMs and other generative models such as video and and audio are going to be so important in the future. To me this is another pillar of computing that will seem mundane in the future like the invention in the database. 

When looking at the existing libraries the big ones are LangChain and LlamaIndex. Even newer ones like the recently released Koog by Jeetbrains follow the same pattern. There seems to be too many classes and provider specific functionality that you have to be an expert in the specific library to use. My measure for a library I want to use is if I see something like `OpenAIExecutor` then I lose interest. I also want to write what looks like regular code as much as possible and not be an expert in the specific library to use. 

At the end of the day we are calling a chat endpoint and getting strings back we should call somehting like `chat(messages, options)`. And so I built a library called `rager` which provides top level functions for interacting with generative models. You can swap out providers with just a string `chat(messages, provider: "openai")` or models `chat(messages, model: "gpt-4o")`. You can see the Ruby version which I developed first [here](https://github.com/mvkvc/rager_rb) as well as the Elixir version which I am currently using for a project [here](https://github.com/mvkvc/rager_ex). 

But the question now is why create another library just for somewhat improved developer ergonomics? If the machines are going to write the code anyway who cares they can deal with all the `Runnables` they want. Well the point of this library is not the actual library itself, that has been reinvented with slightly different names for the same thing dozens of times at this point. The point is that by developing my own library, I can create a logging server and optimize the library to work as well as possible with this server. The main problem with all the AI coding tools availble on the market today, props to my personal favourite [Cline](https://cline.bot), is that you do not capture the outputs of using these agents. And I don't mean this in a privacy sense, if you are privacy sensitive with your coding then you should deploy something in house anyways. But you are providing the most valuable feedback for coding agents which is doing economically valuable work, and you are paying them for the priviledge to do so. 

If we look out a few years from now these companies will have such a rich dataset on your coding activity that they will sell you back your data in the form of custom model adapters or few shot context hidden in the app and it will be noticeably better than just the base model that they will have really strong pricing power. So I've decided that since I use these tools so much I want to collect the outcome of my work and increase my leverage over time by getting more data of the way I like to work.
